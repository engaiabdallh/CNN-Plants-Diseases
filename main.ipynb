{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjXVo3dNdgAa",
        "outputId": "eb9e9430-f684-480e-921b-1e3517955a23"
      },
      "outputs": [],
      "source": [
        "# !pip install opendatasets --quiet\n",
        "# import opendatasets as od\n",
        "# od.download(\"https://www.kaggle.com/datasets/abdallahalidev/plantvillage-dataset\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "nrKxKLt4du9J"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, random_split, WeightedRandomSampler\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import os\n",
        "from collections import Counter  # ADD THIS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nxpT27Vkdvpo"
      },
      "outputs": [],
      "source": [
        "# ============================\n",
        "# 2. CONSTANTS (HYPERPARAMETERS)\n",
        "# ============================\n",
        "BATCH_SIZE = 32\n",
        "IMAGE_SIZE = 380\n",
        "CHANNEL = 3\n",
        "EPOCHS = 20\n",
        "DATA_PATH = r\"Plants\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AOx4RFICdyTg",
        "outputId": "e36f54a3-6996-48e4-90a0-9609a0e3c5a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "# ADD DEVICE SETTING\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6AHs0Xid45A",
        "outputId": "dd4d9c79-af67-4d59-9670-5d3fd1f8e01f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== CALCULATING CLASS WEIGHTS FOR IMBALANCE ===\n",
            "  Apple___Apple_scab: 630 images\n",
            "  Apple___Black_rot: 621 images\n",
            "  Apple___Cedar_apple_rust: 275 images\n",
            "  Apple___healthy: 1645 images\n",
            "  Cherry_(including_sour)___Powdery_mildew: 1052 images\n",
            "  Cherry_(including_sour)___healthy: 854 images\n",
            "  Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot: 513 images\n",
            "  Corn_(maize)___Common_rust_: 1192 images\n",
            "  Corn_(maize)___Northern_Leaf_Blight: 985 images\n",
            "  Corn_(maize)___healthy: 1162 images\n",
            "  Grape___Black_rot: 1180 images\n",
            "  Grape___Esca_(Black_Measles): 1383 images\n",
            "  Grape___Leaf_blight_(Isariopsis_Leaf_Spot): 1076 images\n",
            "  Grape___healthy: 423 images\n",
            "  Peach___Bacterial_spot: 2297 images\n",
            "  Peach___healthy: 360 images\n",
            "  Pepper,_bell___Bacterial_spot: 997 images\n",
            "  Pepper,_bell___healthy: 1478 images\n",
            "  Potato___Early_blight: 1000 images\n",
            "  Potato___Late_blight: 1000 images\n",
            "  Potato___healthy: 152 images\n",
            "  Strawberry___Leaf_scorch: 1109 images\n",
            "  Strawberry___healthy: 456 images\n",
            "  Tomato___Bacterial_spot: 2127 images\n",
            "  Tomato___Early_blight: 1000 images\n",
            "  Tomato___Late_blight: 1909 images\n",
            "  Tomato___Leaf_Mold: 952 images\n",
            "  Tomato___Septoria_leaf_spot: 1771 images\n",
            "  Tomato___Spider_mites Two-spotted_spider_mite: 1676 images\n",
            "  Tomato___Target_Spot: 1404 images\n",
            "  Tomato___Tomato_Yellow_Leaf_Curl_Virus: 5357 images\n",
            "  Tomato___Tomato_mosaic_virus: 373 images\n",
            "  Tomato___healthy: 1591 images\n"
          ]
        }
      ],
      "source": [
        "# Load dataset\n",
        "dataset = datasets.ImageFolder(DATA_PATH)\n",
        "\n",
        "# ============================\n",
        "# NEW: CALCULATE CLASS WEIGHTS\n",
        "# ============================\n",
        "print(\"\\n=== CALCULATING CLASS WEIGHTS FOR IMBALANCE ===\")\n",
        "# Get class counts\n",
        "class_counts = {}\n",
        "for class_name in dataset.classes:\n",
        "    class_path = os.path.join(DATA_PATH, class_name)\n",
        "    count = len([f for f in os.listdir(class_path)])\n",
        "    class_counts[class_name] = count\n",
        "    print(f\"  {class_name}: {count} images\")\n",
        "\n",
        "# Calculate class weights (inverse frequency)\n",
        "class_weights = []\n",
        "for idx, class_name in enumerate(dataset.classes):\n",
        "    weight = 1.0 / class_counts[class_name]  # Smaller class = higher weight\n",
        "    class_weights.append(weight)\n",
        "\n",
        "# Convert to tensor for loss function\n",
        "class_weights_tensor = torch.tensor(class_weights, device=device)\n",
        "\n",
        "# Calculate weights for WeightedRandomSampler\n",
        "sample_weights = []\n",
        "for _, label in dataset:\n",
        "    sample_weights.append(class_weights[label])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4Dh46KXd76A",
        "outputId": "6cf9e791-8fd5-430e-829d-b93d2c3dcf7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Dataset split:\n",
            "  Train: 28000 samples\n",
            "  Val: 6000 samples\n",
            "  Test: 6000 samples\n"
          ]
        }
      ],
      "source": [
        "# ============================\n",
        "# NEW: STRATIFIED SPLIT\n",
        "# ============================\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Get indices and labels\n",
        "indices = list(range(len(dataset)))\n",
        "labels = [label for _, label in dataset]\n",
        "\n",
        "# Split with stratification\n",
        "train_indices, temp_indices = train_test_split(\n",
        "    indices, test_size=0.3, random_state=42, stratify=labels\n",
        ")\n",
        "val_indices, test_indices = train_test_split(\n",
        "    temp_indices, test_size=0.5, random_state=42,\n",
        "    stratify=[labels[i] for i in temp_indices]\n",
        ")\n",
        "\n",
        "# Create subsets\n",
        "train_data = torch.utils.data.Subset(dataset, train_indices)\n",
        "val_data = torch.utils.data.Subset(dataset, val_indices)\n",
        "test_data = torch.utils.data.Subset(dataset, test_indices)\n",
        "\n",
        "print(f\"\\nDataset split:\")\n",
        "print(f\"  Train: {len(train_data)} samples\")\n",
        "print(f\"  Val: {len(val_data)} samples\")\n",
        "print(f\"  Test: {len(test_data)} samples\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "yuq1YYwzd-cQ"
      },
      "outputs": [],
      "source": [
        "# ============================\n",
        "# 3. TRANSFORMS (RESIZE + NORMALIZE)\n",
        "# ============================\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.RandomRotation(20),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2),  # ADDED\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # ADDED\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # ADDED\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMST-qabd_Hw",
        "outputId": "9198643c-b361-4f41-b09d-e21e18f1a04e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Classes: ['Apple___Apple_scab', 'Apple___Black_rot', 'Apple___Cedar_apple_rust', 'Apple___healthy', 'Cherry_(including_sour)___Powdery_mildew', 'Cherry_(including_sour)___healthy', 'Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot', 'Corn_(maize)___Common_rust_', 'Corn_(maize)___Northern_Leaf_Blight', 'Corn_(maize)___healthy', 'Grape___Black_rot', 'Grape___Esca_(Black_Measles)', 'Grape___Leaf_blight_(Isariopsis_Leaf_Spot)', 'Grape___healthy', 'Peach___Bacterial_spot', 'Peach___healthy', 'Pepper,_bell___Bacterial_spot', 'Pepper,_bell___healthy', 'Potato___Early_blight', 'Potato___Late_blight', 'Potato___healthy', 'Strawberry___Leaf_scorch', 'Strawberry___healthy', 'Tomato___Bacterial_spot', 'Tomato___Early_blight', 'Tomato___Late_blight', 'Tomato___Leaf_Mold', 'Tomato___Septoria_leaf_spot', 'Tomato___Spider_mites Two-spotted_spider_mite', 'Tomato___Target_Spot', 'Tomato___Tomato_Yellow_Leaf_Curl_Virus', 'Tomato___Tomato_mosaic_virus', 'Tomato___healthy']\n",
            "Number of classes: 33\n"
          ]
        }
      ],
      "source": [
        "# ============================\n",
        "# 4. LOAD DATASET\n",
        "# ============================\n",
        "train_data.dataset.transform = train_transform\n",
        "val_data.dataset.transform = test_transform\n",
        "test_data.dataset.transform = test_transform\n",
        "\n",
        "class_names = dataset.classes\n",
        "num_classes = len(class_names)\n",
        "\n",
        "# ============================\n",
        "# NEW: CREATE WEIGHTED SAMPLER FOR TRAINING\n",
        "# ============================\n",
        "# Get weights for train subset only\n",
        "train_sample_weights = [sample_weights[i] for i in train_indices]\n",
        "train_sampler = WeightedRandomSampler(\n",
        "    weights=train_sample_weights,\n",
        "    num_samples=len(train_sample_weights),\n",
        "    replacement=True  # Important for oversampling\n",
        ")\n",
        "\n",
        "# Create DataLoaders\n",
        "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, sampler=train_sampler)  # Use sampler instead of shuffle\n",
        "val_loader = DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=False)\n",
        "test_loader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "print(f\"\\nClasses: {class_names}\")\n",
        "print(f\"Number of classes: {num_classes}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1S1o4E5FeErw",
        "outputId": "e5009f2e-d7c6-400d-a139-9953336f5885"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Alsayad Electronics\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Alsayad Electronics\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B4_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B4_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "# ============================\n",
        "# 5. MODEL\n",
        "# ============================\n",
        "import torchvision.models as models\n",
        "\n",
        "# Load pretrained EfficientNet\n",
        "model = models.efficientnet_b4(pretrained=True)\n",
        "\n",
        "# Freeze all layers\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Replace classifier\n",
        "num_ftrs = model.classifier[1].in_features\n",
        "model.classifier = nn.Sequential(\n",
        "    nn.Dropout(0.3),\n",
        "    nn.Linear(num_ftrs, len(class_names))\n",
        ")\n",
        "\n",
        "# Move model to device\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ltGfJcDteHyY"
      },
      "outputs": [],
      "source": [
        "# ============================\n",
        "# 6. LOSS & OPTIMIZER WITH CLASS WEIGHTS\n",
        "# ============================\n",
        "# Use weighted CrossEntropyLoss\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)  # ADDED CLASS WEIGHTS\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eru08UDxeK0I",
        "outputId": "85bb2f03-eb51-40a1-a631-2bcb071be1b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== STARTING TRAINING ===\n",
            "Epoch 1/20 | Train Loss: 1.0879 | Train Acc: 0.6924 | Val Loss: 0.6522 | Val Acc: 0.8057\n",
            "Epoch 2/20 | Train Loss: 0.3862 | Train Acc: 0.8658 | Val Loss: 0.4349 | Val Acc: 0.8572\n",
            "Epoch 3/20 | Train Loss: 0.2751 | Train Acc: 0.8927 | Val Loss: 0.3499 | Val Acc: 0.8765\n",
            "Epoch 4/20 | Train Loss: 0.2255 | Train Acc: 0.9063 | Val Loss: 0.2952 | Val Acc: 0.8962\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     17\u001b[39m loss.backward()\n\u001b[32m     18\u001b[39m optimizer.step()\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m running_loss += \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m _, preds = torch.max(outputs, \u001b[32m1\u001b[39m)\n\u001b[32m     22\u001b[39m correct += (preds == labels).sum().item()\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "# ============================\n",
        "# 7. TRAINING LOOP\n",
        "# ============================\n",
        "print(\"\\n=== STARTING TRAINING ===\")\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    running_loss = 0\n",
        "    correct = 0\n",
        "    total = 0  # ADDED\n",
        "\n",
        "    for imgs, labels in train_loader:\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(imgs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0) # ADDED(32,)\n",
        "\n",
        "    train_acc = correct / total  # CHANGED: divide by total samples, not batches\n",
        "    train_loss = running_loss / len(train_loader)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_correct = 0\n",
        "    val_loss_total = 0\n",
        "    val_total = 0  # ADDED\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in val_loader:\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            outputs = model(imgs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss_total += loss.item()\n",
        "\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            val_correct += (preds == labels).sum().item()\n",
        "            val_total += labels.size(0)  # ADDED\n",
        "\n",
        "    val_acc = val_correct / val_total  # CHANGED\n",
        "    val_loss = val_loss_total / len(val_loader)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{EPOCHS} | \"\n",
        "          f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | \"\n",
        "          f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5kr06gEeNa4",
        "outputId": "1b48bf8b-4e25-41fb-d37a-3dfe399f7a21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== TEST RESULTS ===\n",
            "Overall Test Accuracy: 0.9507\n",
            "\n",
            "Per-class Test Accuracy:\n",
            "  Apple___Apple_scab: 0.9681 (94 samples)\n",
            "  Apple___Black_rot: 0.9785 (93 samples)\n",
            "  Apple___Cedar_apple_rust: 0.9756 (41 samples)\n",
            "  Apple___healthy: 0.9756 (246 samples)\n",
            "  Blueberry___healthy: 1.0000 (226 samples)\n",
            "  Cherry_(including_sour)___Powdery_mildew: 0.9937 (158 samples)\n",
            "  Cherry_(including_sour)___healthy: 0.9844 (128 samples)\n",
            "  Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot: 0.9351 (77 samples)\n",
            "  Corn_(maize)___Common_rust_: 0.9944 (179 samples)\n",
            "  Corn_(maize)___Northern_Leaf_Blight: 0.8571 (147 samples)\n",
            "  Corn_(maize)___healthy: 1.0000 (174 samples)\n",
            "  Grape___Black_rot: 0.9831 (177 samples)\n",
            "  Grape___Esca_(Black_Measles): 0.9758 (207 samples)\n",
            "  Grape___Leaf_blight_(Isariopsis_Leaf_Spot): 1.0000 (162 samples)\n",
            "  Grape___healthy: 0.9844 (64 samples)\n",
            "  Orange___Haunglongbing_(Citrus_greening): 0.9927 (826 samples)\n",
            "  Peach___Bacterial_spot: 0.9448 (344 samples)\n",
            "  Peach___healthy: 1.0000 (54 samples)\n",
            "  Pepper,_bell___Bacterial_spot: 0.9733 (150 samples)\n",
            "  Pepper,_bell___healthy: 0.9730 (222 samples)\n",
            "  Potato___Early_blight: 0.9867 (150 samples)\n",
            "  Potato___Late_blight: 0.8933 (150 samples)\n",
            "  Potato___healthy: 0.9130 (23 samples)\n",
            "  Raspberry___healthy: 1.0000 (55 samples)\n",
            "  Soybean___healthy: 0.9607 (764 samples)\n",
            "  Squash___Powdery_mildew: 0.9927 (275 samples)\n",
            "  Strawberry___Leaf_scorch: 1.0000 (167 samples)\n",
            "  Strawberry___healthy: 1.0000 (68 samples)\n",
            "  Tomato___Bacterial_spot: 0.9185 (319 samples)\n",
            "  Tomato___Early_blight: 0.8667 (150 samples)\n",
            "  Tomato___Late_blight: 0.8153 (287 samples)\n",
            "  Tomato___Leaf_Mold: 0.9161 (143 samples)\n",
            "  Tomato___Septoria_leaf_spot: 0.8717 (265 samples)\n",
            "  Tomato___Spider_mites Two-spotted_spider_mite: 0.9484 (252 samples)\n",
            "  Tomato___Target_Spot: 0.7915 (211 samples)\n",
            "  Tomato___Tomato_Yellow_Leaf_Curl_Virus: 0.9290 (803 samples)\n",
            "  Tomato___Tomato_mosaic_virus: 1.0000 (56 samples)\n",
            "  Tomato___healthy: 0.9791 (239 samples)\n"
          ]
        }
      ],
      "source": [
        "# ============================\n",
        "# 8. EVALUATE MODEL (WITH PER-CLASS ACCURACY)\n",
        "# ============================\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "# ADDED: Track per-class accuracy\n",
        "class_correct = [0] * num_classes\n",
        "class_total = [0] * num_classes\n",
        "\n",
        "with torch.no_grad():\n",
        "    for imgs, labels in test_loader:\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "        outputs = model(imgs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)#â†’ the first dimension, which is the batch size(32,)\n",
        "\n",
        "        # ADDED: Count per-class\n",
        "        for i in range(num_classes):\n",
        "            idx = (labels == i)\n",
        "            if idx.sum().item() > 0:\n",
        "                class_correct[i] += (preds[idx] == labels[idx]).sum().item()\n",
        "                class_total[i] += idx.sum().item()\n",
        "\n",
        "print(f\"\\n=== TEST RESULTS ===\")\n",
        "print(f\"Overall Test Accuracy: {correct / total:.4f}\")\n",
        "\n",
        "# ADDED: Print per-class accuracy\n",
        "print(\"\\nPer-class Test Accuracy:\")\n",
        "for i in range(num_classes):\n",
        "    if class_total[i] > 0:\n",
        "        acc = class_correct[i] / class_total[i]\n",
        "        print(f\"  {class_names[i]}: {acc:.4f} ({class_total[i]} samples)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ON7VuuCtdprK",
        "outputId": "01e32561-f689-482b-8949-5bd4d37169f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Model saved!\n"
          ]
        }
      ],
      "source": [
        "# ============================\n",
        "# 9. SAVE MODEL\n",
        "# ============================\n",
        "torch.save(model.state_dict(), \"model_imbalanced.pth\")\n",
        "print(\"\\nModel saved!\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
